{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T04:49:02.788219Z",
     "iopub.status.busy": "2022-08-03T04:49:02.787067Z",
     "iopub.status.idle": "2022-08-03T04:49:08.816611Z",
     "shell.execute_reply": "2022-08-03T04:49:08.815612Z",
     "shell.execute_reply.started": "2022-08-03T04:49:02.788060Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T04:49:08.819184Z",
     "iopub.status.busy": "2022-08-03T04:49:08.818453Z",
     "iopub.status.idle": "2022-08-03T04:49:12.447765Z",
     "shell.execute_reply": "2022-08-03T04:49:12.446836Z",
     "shell.execute_reply.started": "2022-08-03T04:49:08.819127Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_real = np.load('../input/dataset-z/x_real.npz')['data']\n",
    "y_real = np.load('../input/dataset-z/y_real.npy')\n",
    "\n",
    "x_zoom = np.load('../input/dataset-z/x_zoom.npz')['data']\n",
    "y_zoom = np.load('../input/dataset-z/y_zoom.npy')\n",
    "\n",
    "x_partial = np.load('../input/dataset-z/x_partial.npz')['data']\n",
    "y_partial = np.load('../input/dataset-z/y_partial.npy')\n",
    "\n",
    "print(x_zoom.shape, y_zoom.shape)\n",
    "print(x_partial.shape, y_partial.shape)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(y_real[0])\n",
    "plt.imshow(x_real[0].squeeze(), cmap='gray')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(y_zoom[0])\n",
    "plt.imshow(x_zoom[0].squeeze(), cmap='gray')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(y_partial[0])\n",
    "plt.imshow(x_partial[0].squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T04:49:15.255424Z",
     "iopub.status.busy": "2022-08-03T04:49:15.254841Z",
     "iopub.status.idle": "2022-08-03T04:49:15.316869Z",
     "shell.execute_reply": "2022-08-03T04:49:15.315842Z",
     "shell.execute_reply.started": "2022-08-03T04:49:15.255389Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_val, label_train, label_val = train_test_split(x_zoom, y_zoom, test_size=0.1)\n",
    "\n",
    "print(x_zoom.shape, y_zoom.shape)\n",
    "print(x_train.shape, label_train.shape)\n",
    "print(x_val.shape, label_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Label Dictionary Lookup Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T04:49:17.546195Z",
     "iopub.status.busy": "2022-08-03T04:49:17.545179Z",
     "iopub.status.idle": "2022-08-03T04:49:17.588387Z",
     "shell.execute_reply": "2022-08-03T04:49:17.587446Z",
     "shell.execute_reply.started": "2022-08-03T04:49:17.546119Z"
    }
   },
   "outputs": [],
   "source": [
    "# ID(3)性別(1)左右(1)指頭(1): index\n",
    "# {'100001': 0, '100004': 1, '100002': 2, ....}\n",
    "label_real_dict = {}\n",
    "\n",
    "for i, y in enumerate(y_real):\n",
    "    key = y.astype(str)\n",
    "    key = ''.join(key).zfill(6)\n",
    "\n",
    "    label_real_dict[key] = i\n",
    "len(label_real_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T04:49:19.730358Z",
     "iopub.status.busy": "2022-08-03T04:49:19.729992Z",
     "iopub.status.idle": "2022-08-03T04:49:19.746397Z",
     "shell.execute_reply": "2022-08-03T04:49:19.745423Z",
     "shell.execute_reply.started": "2022-08-03T04:49:19.730326Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.all_utils.Sequence):\n",
    "    def __init__(self, x, label, x_real, label_real_dict, batch_size=32, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.x = x\n",
    "        self.label = label\n",
    "        self.x_real = x_real\n",
    "        self.label_real_dict = label_real_dict\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.x) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        x1_batch = self.x[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        label_batch = self.label[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        x2_batch = np.empty((self.batch_size, 96, 96), dtype=np.float32)\n",
    "        y_batch = np.zeros((self.batch_size, 1), dtype=np.float32)\n",
    "        \n",
    "        # augmentation\n",
    "        if self.shuffle:\n",
    "            seq = iaa.Sequential([\n",
    "                iaa.GaussianBlur(sigma=(0, 0.5)),\n",
    "                iaa.Affine(\n",
    "                    scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "                    translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
    "                    rotate=(-30, 30),\n",
    "                    order=[0, 1],\n",
    "                    cval=255\n",
    "                )\n",
    "            ], random_order=True)\n",
    "\n",
    "            x1_batch = seq.augment_images(x1_batch)\n",
    "        \n",
    "        # pick matched images(label 1.0) and unmatched images(label 0.0) and put together in batch\n",
    "        # matched images must be all same, [subject_id(3), gender(1), left_right(1), finger(1)], e.g) 034010\n",
    "        for i, l in enumerate(label_batch):\n",
    "            match_key = l.astype(str)\n",
    "            match_key = ''.join(match_key).zfill(6)\n",
    "\n",
    "            if random.random() > 0.5:\n",
    "                # put matched image\n",
    "                x2_batch[i] = self.x_real[self.label_real_dict[match_key]]\n",
    "                y_batch[i] = 1.\n",
    "            else:\n",
    "                # put unmatched image\n",
    "                while True:\n",
    "                    unmatch_key, unmatch_idx = random.choice(list(self.label_real_dict.items()))\n",
    "\n",
    "                    if unmatch_key != match_key:\n",
    "                        break\n",
    "\n",
    "                x2_batch[i] = self.x_real[unmatch_idx]\n",
    "                y_batch[i] = 0.\n",
    "        \n",
    "        return [x1_batch.astype(np.float32) / 255., x2_batch.astype(np.float32) / 255.], y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle == True:\n",
    "            self.x, self.label = shuffle(self.x, self.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T04:49:22.850942Z",
     "iopub.status.busy": "2022-08-03T04:49:22.850331Z",
     "iopub.status.idle": "2022-08-03T04:49:22.909361Z",
     "shell.execute_reply": "2022-08-03T04:49:22.908230Z",
     "shell.execute_reply.started": "2022-08-03T04:49:22.850905Z"
    }
   },
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(x_train, label_train, x_real, label_real_dict, shuffle=True)\n",
    "val_gen = DataGenerator(x_val, label_val, x_real, label_real_dict, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T04:49:25.598479Z",
     "iopub.status.busy": "2022-08-03T04:49:25.597974Z",
     "iopub.status.idle": "2022-08-03T04:49:28.804440Z",
     "shell.execute_reply": "2022-08-03T04:49:28.803445Z",
     "shell.execute_reply.started": "2022-08-03T04:49:25.598438Z"
    }
   },
   "outputs": [],
   "source": [
    "x1 = layers.Input(shape=(96, 96, 1))\n",
    "x2 = layers.Input(shape=(96, 96, 1))\n",
    "\n",
    "# share weights both inputs\n",
    "inputs = layers.Input(shape=(96, 96, 1))\n",
    "\n",
    "feature = layers.Conv2D(32, kernel_size=3, padding='same', activation='relu')(inputs)\n",
    "feature = layers.MaxPooling2D(pool_size=2)(feature)\n",
    "\n",
    "feature = layers.Conv2D(32, kernel_size=3, padding='same', activation='relu')(feature)\n",
    "feature = layers.MaxPooling2D(pool_size=2)(feature)\n",
    "\n",
    "feature = layers.Conv2D(32, kernel_size=3, padding='same', activation='relu')(feature)\n",
    "feature = layers.MaxPooling2D(pool_size=2)(feature)\n",
    "\n",
    "feature_model = Model(inputs=inputs, outputs=feature)\n",
    "\n",
    "# 2 feature models that sharing weights\n",
    "x1_net = feature_model(x1)\n",
    "x2_net = feature_model(x2)\n",
    "\n",
    "# subtract features\n",
    "net = layers.Subtract()([x1_net, x2_net])\n",
    "net = layers.Conv2D(32, kernel_size=3, padding='same', activation='relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=2)(net)\n",
    "net = layers.Flatten()(net)\n",
    "net = layers.Dense(64, activation='relu')(net)\n",
    "net = layers.Dense(1, activation='sigmoid')(net)\n",
    "\n",
    "model = Model(inputs=[x1, x2], outputs=net)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T04:50:15.257077Z",
     "iopub.status.busy": "2022-08-03T04:50:15.256317Z",
     "iopub.status.idle": "2022-08-03T04:55:53.400958Z",
     "shell.execute_reply": "2022-08-03T04:55:53.397697Z",
     "shell.execute_reply.started": "2022-08-03T04:50:15.257038Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "# 建立 EarlyStopping 物件\n",
    "es = EarlyStopping(monitor='val_loss', mode='min',\n",
    "                  verbose=1, patience=5)\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "# 建立 ModelCheckpoint 物件\n",
    "filename = './data/Siamese_zoom.h5'\n",
    "# filename = './data/Siamese_zoom.hdf5' # val_accuracy\n",
    "mc = ModelCheckpoint(filename, monitor='val_acc',\n",
    "                    mode='max', verbose=0,\n",
    "                    save_best_only=True)\n",
    "\n",
    "history = model.fit(train_gen, epochs=100, validation_data=val_gen, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 儲存Keras模型\n",
    "# print('Saving Model: Siamese_zoom.h5 ...')\n",
    "# model.save('./data/Siamese_zoom.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model =  keras.models.load_model('./data/Siamese_zoom.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T05:04:08.730986Z",
     "iopub.status.busy": "2022-08-03T05:04:08.730259Z",
     "iopub.status.idle": "2022-08-03T05:04:08.737558Z",
     "shell.execute_reply": "2022-08-03T05:04:08.736585Z",
     "shell.execute_reply.started": "2022-08-03T05:04:08.730947Z"
    }
   },
   "outputs": [],
   "source": [
    "match = np.ones((6000,1))\n",
    "match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T05:04:11.131719Z",
     "iopub.status.busy": "2022-08-03T05:04:11.131194Z",
     "iopub.status.idle": "2022-08-03T05:04:14.015776Z",
     "shell.execute_reply": "2022-08-03T05:04:14.014785Z",
     "shell.execute_reply.started": "2022-08-03T05:04:11.131686Z"
    }
   },
   "outputs": [],
   "source": [
    "# 評估模型\n",
    "print('\\nTesting ...')\n",
    "loss, accuracy = model.evaluate([x_partial.astype(np.float32) / 255.,x_real.astype(np.float32) / 255.], match, verbose=1)\n",
    "print('測試資料集的準確度 = {:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T05:04:30.433152Z",
     "iopub.status.busy": "2022-08-03T05:04:30.432766Z",
     "iopub.status.idle": "2022-08-03T05:04:30.890006Z",
     "shell.execute_reply": "2022-08-03T05:04:30.889027Z",
     "shell.execute_reply.started": "2022-08-03T05:04:30.433099Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 顯示訓練和驗證損失\n",
    "loss = history.history['loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "val_loss = history.history['val_loss']\n",
    "plt.plot(epochs, loss, 'bo-', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'ro--', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# 顯示訓練和驗證準確度 注意 accyracy 要改成 acc，val_accuracy => val_acc，因為keras版本問題\n",
    "acc = history.history['acc']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "val_acc = history.history['val_acc']\n",
    "plt.plot(epochs, acc, 'bo-', label='Training Acc')\n",
    "plt.plot(epochs, val_acc, 'ro--', label='Validation Acc')\n",
    "plt.title('Training and Validation Acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T05:04:35.970927Z",
     "iopub.status.busy": "2022-08-03T05:04:35.970564Z",
     "iopub.status.idle": "2022-08-03T05:04:36.432984Z",
     "shell.execute_reply": "2022-08-03T05:04:36.432049Z",
     "shell.execute_reply.started": "2022-08-03T05:04:35.970896Z"
    }
   },
   "outputs": [],
   "source": [
    "# new user fingerprint input\n",
    "random_idx = random.randint(0, len(x_partial))\n",
    "\n",
    "random_img = x_partial[random_idx]\n",
    "random_label = y_partial[random_idx]\n",
    "\n",
    "random_img = random_img.reshape((1, 96, 96, 1)).astype(np.float32) / 255.\n",
    "\n",
    "# matched image\n",
    "match_key = random_label.astype(str)\n",
    "match_key = ''.join(match_key).zfill(6)\n",
    "\n",
    "rx = x_real[label_real_dict[match_key]].reshape((1, 96, 96, 1)).astype(np.float32) / 255.\n",
    "ry = y_real[label_real_dict[match_key]]\n",
    "\n",
    "pred_rx = model.predict([random_img, rx])\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Input: %s' %random_label)\n",
    "plt.imshow(random_img.squeeze(), cmap='gray')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Real: %.02f, %s' % (pred_rx, ry))\n",
    "plt.imshow(rx.squeeze(), cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
